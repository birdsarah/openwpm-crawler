apiVersion: batch/v1
kind: Job
metadata:
  name: local-crawl
spec:
  # adjust for parallelism
  parallelism: 2
  template:
    metadata:
      name: openwpm-crawl
    spec:
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
      containers:
      - name: openwpm-crawl
        image: openwpm
        command: ["python"]
        args: ["crawler.py"]
        imagePullPolicy: Never # allows use of a locally built/tagged docker image
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
        env:
        - name: AWS_ACCESS_KEY_ID
          value: 'foo'
        - name: AWS_SECRET_ACCESS_KEY
          value: 'foo'
        - name: REDIS_QUEUE_NAME
          value: 'crawl-queue'
        - name: CRAWL_DIRECTORY
          value: 'openwpm-crawl'
        - name: S3_BUCKET
          value: 'localstack-foo'
        - name: S3_ENDPOINT
          value: 'http://localstack:4572'
        - name: HTTP_INSTRUMENT
          value: '1'
        - name: COOKIE_INSTRUMENT
          value: '1'
        - name: NAVIGATION_INSTRUMENT
          value: '1'
        - name: JS_INSTRUMENT
          value: '1'
        - name: SAVE_JAVASCRIPT
          value: '1'
        - name: DWELL_TIME
          value: '10'
        - name: TIMEOUT
          value: '60'
        - name: LOG_LEVEL_CONSOLE
          value: 'DEBUG'
        - name: LOG_LEVEL_FILE
          value: 'DEBUG'
        - name: MAX_JOB_RETRIES
          value: '2'
      restartPolicy: OnFailure
